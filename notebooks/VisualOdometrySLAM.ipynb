{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5056017",
   "metadata": {},
   "source": [
    "# VisualOdometrySLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec744062",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdb9fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cv2.setRNGSeed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5d89657",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6038a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('../data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_VIDEO = DATA_PATH /Path('visual_odometry/')\n",
    "DATA_PATH_VIDEO.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_OUTPUT = DATA_PATH / Path('output_data/')\n",
    "DATA_PATH_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = DATA_PATH / Path('models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_IMGS = Path('../imgs')\n",
    "DATA_IMGS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d1cd074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e3e3a",
   "metadata": {},
   "source": [
    "## –û–±—â–∏–µ –º–µ—Ç–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efad5d8",
   "metadata": {},
   "source": [
    "| –ü–∞—Ä–∞–º–µ—Ç—Ä                  | –ì–¥–µ –≤ YAML                     | –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç                                  | –ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å / –æ—Ç–∫—É–¥–∞ –±–µ—Ä—ë—Ç—Å—è                 |\n",
    "| ------------------------- | ------------------------------ | --------------------------------------------- | ----------------------------------------------- |\n",
    "| `fx`, `fy`                | `camera_matrix.data[0]`, `[4]` | –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ –æ—Å—è–º X –∏ Y             | –ò–∑ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `cv2.calibrateCamera`) |\n",
    "| `cx`, `cy`                | `camera_matrix.data[2]`, `[5]` | –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≥–ª–∞–≤–Ω–æ–π —Ç–æ—á–∫–∏ (–æ–ø—Ç–∏—á–µ—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä)   | –¶–µ–Ω—Ç—Ä –∫–∞–¥—Ä–∞ –∏–ª–∏ –∏–∑ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏                   |\n",
    "| `camera_matrix`           | `camera_matrix.data`           | –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –º–∞—Ç—Ä–∏—Ü–∞ 3√ó3                        | –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏                            |\n",
    "| `distortion_model`        | `distortion_model`             | –ú–æ–¥–µ–ª—å –¥–∏—Å—Ç–æ—Ä—Å–∏–∏ (`plumb_bob`, `equidistant`) | –í—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø—Ä–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ, –ø–æ —Ç–∏–ø—É –æ–±—ä–µ–∫—Ç–∏–≤–∞    |\n",
    "| `distortion_coefficients` | `distortion_coefficients.data` | –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∏—Å–∫–∞–∂–µ–Ω–∏–π (k1, k2, p1, p2, k3)   | –í—ã—Ö–æ–¥ `cv2.calibrateCamera`, `Kalibr`, ROS      |\n",
    "| `image_width` / `height`  | `image_width`, `image_height`  | –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)               | –ò–∑–≤–µ—Å—Ç–Ω–æ –ø–æ —Å–µ–Ω—Å–æ—Ä—É –∏–ª–∏ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏   |\n",
    "| `camera_name`             | `camera_name`                  | –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–º–µ—Ä—ã                               | –ó–∞–¥–∞—ë—Ç—Å—è –≤—Ä—É—á–Ω—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "201accc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "\n",
    "\n",
    "def load_video_frames(video_path: Union[str, Path], target_fps: float) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ —Å –∑–∞–¥–∞–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –∏—Ö –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ.\n",
    "\n",
    "    :param video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É\n",
    "    :param target_fps: —Ü–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤\n",
    "    :return: —Å–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤ (–≤ –æ—Ç—Ç–µ–Ω–∫–∞—Ö —Å–µ—Ä–æ–≥–æ)\n",
    "    \"\"\"\n",
    "    video_path = Path(video_path)\n",
    "    if not video_path.exists():\n",
    "        raise FileNotFoundError(f'–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {video_path.resolve()}')\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f'–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}')\n",
    "\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(video_fps / target_fps)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration_sec = total_frames / video_fps\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f\"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ:\")\n",
    "    print(f\"- –ò–º—è —Ñ–∞–π–ª–∞: {video_path.name}\")\n",
    "    print(f\"- –†–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞: {frame_width} x {frame_height}\")\n",
    "    print(f\"- –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π FPS: {video_fps:.2f}\")\n",
    "    print(f\"- –û–±—â–µ–µ —á–∏—Å–ª–æ –∫–∞–¥—Ä–æ–≤: {total_frames}\")\n",
    "    print(f\"- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ: {duration_sec:.2f} —Å–µ–∫—É–Ω–¥\")\n",
    "    print(f\"- –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {target_fps} FPS\")\n",
    "    print(f\"- –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∫–∞–∂–¥—ã–π {frame_interval}-–π –∫–∞–¥—Ä\")\n",
    "\n",
    "    processed_frames = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            processed_frames.append(gray)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {len(processed_frames)} –ø—Ä–∏ —Ü–µ–ª–µ–≤–æ–º FPS: {target_fps}\")\n",
    "    return processed_frames\n",
    "\n",
    "\n",
    "def load_kitti_sequence(path: Union[str, Path], grayscale: bool = True) -> List[np.ndarray]:\n",
    "    image_paths = sorted(Path(path).glob(\"*.png\"))\n",
    "    frames = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE if grayscale else cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            frames.append(img)\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2a6ac",
   "metadata": {},
   "source": [
    "## ORB params\n",
    "\n",
    "| –ü–∞—Ä–∞–º–µ—Ç—Ä        | –¢–∏–ø     | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é  | –û–ø–∏—Å–∞–Ω–∏–µ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏                                                                                                         |\n",
    "| --------------- | ------- | ---------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `nfeatures`     | `int`   | 500                    | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á, –∫–æ—Ç–æ—Ä—ã–µ ORB –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏. <br>üîß –£–≤–µ–ª–∏—á—å –¥–æ 3000‚Äì5000 –¥–ª—è –±–æ–≥–∞—Ç–æ–π —Å—Ü–µ–Ω—ã –∏–ª–∏ —Å–µ—Ç–æ—á–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏. |\n",
    "| `scaleFactor`   | `float` | 1.2                    | –ú–∞—Å—à—Ç–∞–± –º–µ–∂–¥—É —É—Ä–æ–≤–Ω—è–º–∏ –ø–∏—Ä–∞–º–∏–¥—ã. <br>–ú–µ–Ω—å—à–µ ‚Äî –±–æ–ª—å—à–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π, –ª—É—á—à–µ –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω—ã—Ö —Å—Ü–µ–Ω, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ.                       |\n",
    "| `nlevels`       | `int`   | 8                      | –ö–æ–ª-–≤–æ —É—Ä–æ–≤–Ω–µ–π –≤ –ø–∏—Ä–∞–º–∏–¥–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. <br>üîß –£–≤–µ–ª–∏—á—å –¥–æ 12‚Äì16, –µ—Å–ª–∏ –æ–∂–∏–¥–∞–µ—Ç—Å—è –º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –æ–±—ä–µ–∫—Ç–æ–≤.                    |\n",
    "| `edgeThreshold` | `int`   | 31                     | –û—Ç—Å—Ç—É–ø –æ—Ç –≥—Ä–∞–Ω–∏—Ü –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. <br>üîß –£–º–µ–Ω—å—à–∏ –¥–æ 10‚Äì15, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –Ω–∞—Ö–æ–¥–∏—Ç—å —Ñ–∏—á–∏ —É –∫—Ä–∞—ë–≤.                                       |\n",
    "| `firstLevel`    | `int`   | 0                      | –ù–∞—á–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø–∏—Ä–∞–º–∏–¥—ã (–æ–±—ã—á–Ω–æ 0). –ü–æ—á—Ç–∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è.                                                               |\n",
    "| `WTA_K`         | `int`   | 2                      | –ú–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ BRIEF-–¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞: 2 = –±—ã—Å—Ç—Ä–µ–µ, 3 –∏–ª–∏ 4 = —Ç–æ—á–Ω–µ–µ. <br>–ò—Å–ø–æ–ª—å–∑—É–π 2, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é.                |\n",
    "| `scoreType`     | `int`   | `cv2.ORB_HARRIS_SCORE` | –í—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è —É–≥–ª–æ–≤: `cv2.ORB_HARRIS_SCORE` –∏–ª–∏ `cv2.ORB_FAST_SCORE`. <br>`HARRIS` —Ç–æ—á–Ω–µ–µ, `FAST` ‚Äî –±—ã—Å—Ç—Ä–µ–µ.       |\n",
    "| `patchSize`     | `int`   | 31                     | –†–∞–∑–º–µ—Ä –æ–±–ª–∞—Å—Ç–∏ –≤–æ–∫—Ä—É–≥ —Ñ–∏—á–∏ –¥–ª—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞. <br>üîß 31 ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 49, –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –∫—Ä—É–ø–Ω—ã–π.                   |\n",
    "| `fastThreshold` | `int`   | 20                     | –ü–æ—Ä–æ–≥ FAST-—É–≥–ª–∞: —á–µ–º –º–µ–Ω—å—à–µ ‚Äî —Ç–µ–º –±–æ–ª—å—à–µ —Ñ–∏—á. <br>üîß –°–Ω–∏–∑—å –¥–æ 5‚Äì10, –µ—Å–ª–∏ ORB –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Ñ–∏—á–∏.                                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b420cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Union, List, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7427b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapPoint:\n",
    "    def __init__(self, coord_3d: np.ndarray, descriptor: np.ndarray):\n",
    "        self.coord = coord_3d  # (X, Y, Z)\n",
    "        self.descriptor = descriptor\n",
    "        self.observations = []  # —Å–ø–∏—Å–æ–∫ (frame_idx, keypoint_idx, (x, y))\n",
    "\n",
    "\n",
    "class KeyFrame:\n",
    "    def __init__(self, frame_id: int, image: np.ndarray, keypoints, descriptors, pose: np.ndarray):\n",
    "        self.id = frame_id\n",
    "        self.image = image\n",
    "        self.keypoints = keypoints\n",
    "        self.descriptors = descriptors\n",
    "        self.pose = pose        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9284bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class MatcherFilterMixin:\n",
    "    @staticmethod\n",
    "    def filter_by_ratio_test(knn_matches, kp1, kp2, ratio_thresh):\n",
    "        good_matches = []\n",
    "        pts1, pts2 = [], []\n",
    "\n",
    "        for pair in knn_matches:\n",
    "            if len(pair) < 2:\n",
    "                continue\n",
    "            m, n = pair\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                good_matches.append(m)\n",
    "                pts1.append(kp1[m.queryIdx].pt)\n",
    "                pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "        return good_matches, np.float32(pts1), np.float32(pts2)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_by_max_distance(matches, pts1, pts2, max_dist):\n",
    "        filtered_matches = []\n",
    "        filtered_pts1, filtered_pts2 = [], []\n",
    "\n",
    "        for i, m in enumerate(matches):\n",
    "            if m.distance < max_dist:\n",
    "                filtered_matches.append(m)\n",
    "                filtered_pts1.append(pts1[i])\n",
    "                filtered_pts2.append(pts2[i])\n",
    "\n",
    "        return filtered_matches, np.float32(filtered_pts1), np.float32(filtered_pts2)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_unique_matches(matches, pts1, pts2):\n",
    "        seen_trainIdx = set()\n",
    "        unique_matches = []\n",
    "        unique_pts1, unique_pts2 = [], []\n",
    "\n",
    "        for i, m in enumerate(matches):\n",
    "            if m.trainIdx not in seen_trainIdx:\n",
    "                seen_trainIdx.add(m.trainIdx)\n",
    "                unique_matches.append(m)\n",
    "                unique_pts1.append(pts1[i])\n",
    "                unique_pts2.append(pts2[i])\n",
    "\n",
    "        return unique_matches, np.float32(unique_pts1), np.float32(unique_pts2)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_by_ransac_fundamental(matches, pts1, pts2):\n",
    "        if len(matches) < 8:\n",
    "            return [], np.array([]), np.array([])\n",
    "\n",
    "        F, mask = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC, ransacReprojThreshold=1.0)\n",
    "\n",
    "        inlier_matches = []\n",
    "        inlier_pts1, inlier_pts2 = [], []\n",
    "\n",
    "        if mask is not None:\n",
    "            for i, m in enumerate(matches):\n",
    "                if mask[i]:\n",
    "                    inlier_matches.append(m)\n",
    "                    inlier_pts1.append(pts1[i])\n",
    "                    inlier_pts2.append(pts2[i])\n",
    "\n",
    "        return inlier_matches, np.float32(inlier_pts1), np.float32(inlier_pts2)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_by_exclusion_mask(matches, pts1, pts2, mask_exclude_regions: List[Tuple[int, int, int, int]]):\n",
    "        if not mask_exclude_regions:\n",
    "            return matches, pts1, pts2\n",
    "\n",
    "        filtered_matches = []\n",
    "        filtered_pts1 = []\n",
    "        filtered_pts2 = []\n",
    "\n",
    "        for i, m in enumerate(matches):\n",
    "            x1, y1 = pts1[i]\n",
    "            x2, y2 = pts2[i]\n",
    "\n",
    "            excluded = any(\n",
    "                (xmin <= x1 <= xmax and ymin <= y1 <= ymax) or\n",
    "                (xmin <= x2 <= xmax and ymin <= y2 <= ymax)\n",
    "                for (xmin, ymin, xmax, ymax) in mask_exclude_regions\n",
    "            )\n",
    "\n",
    "            if not excluded:\n",
    "                filtered_matches.append(m)\n",
    "                filtered_pts1.append((x1, y1))\n",
    "                filtered_pts2.append((x2, y2))\n",
    "\n",
    "        return filtered_matches, np.float32(filtered_pts1), np.float32(filtered_pts2)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_mutual_matches(\n",
    "        matcher: cv2.DescriptorMatcher,\n",
    "        des1: np.ndarray,\n",
    "        des2: np.ndarray,\n",
    "        kp1: List[cv2.KeyPoint],\n",
    "        kp2: List[cv2.KeyPoint],\n",
    "        matches: List[cv2.DMatch],\n",
    "        pts1: np.ndarray,\n",
    "        pts2: np.ndarray\n",
    "    ) -> Tuple[List[cv2.DMatch], np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –≤–∑–∞–∏–º–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (A‚ÜíB –∏ B‚ÜíA).\n",
    "        \n",
    "        :param matcher: –æ–±—ä–µ–∫—Ç cv2.DescriptorMatcher (–Ω–∞–ø—Ä–∏–º–µ—Ä, BFMatcher –∏–ª–∏ FlannBasedMatcher)\n",
    "        :param des1: –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :param des2: –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :param kp1: –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :param kp2: –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :param matches: –ø—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è A‚ÜíB\n",
    "        :param pts1: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫ –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :param pts2: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫ –≤—Ç–æ—Ä–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        :return: (–≤–∑–∞–∏–º–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, pts1, pts2)\n",
    "        \"\"\"\n",
    "        reverse_matches = matcher.match(des2, des1)\n",
    "        reverse_set = {(m.trainIdx, m.queryIdx) for m in reverse_matches}\n",
    "\n",
    "        mutual_matches = []\n",
    "        mutual_pts1, mutual_pts2 = [], []\n",
    "\n",
    "        for i, m in enumerate(matches):\n",
    "            if (m.queryIdx, m.trainIdx) in reverse_set:\n",
    "                mutual_matches.append(m)\n",
    "                mutual_pts1.append(pts1[i])\n",
    "                mutual_pts2.append(pts2[i])\n",
    "\n",
    "        return mutual_matches, np.float32(mutual_pts1), np.float32(mutual_pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6988341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regex import F\n",
    "\n",
    "\n",
    "class VisualOdometry(MatcherFilterMixin):\n",
    "    def __init__(self, \n",
    "                 video_path: Union[str, Path],\n",
    "                 calibration_file: Union[str, Path],                   \n",
    "                 **params) -> None:\n",
    "        \"\"\"\n",
    "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –æ–¥–æ–º–µ—Ç—Ä–∏–∏.\n",
    "\n",
    "        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∫–∞–º–µ—Ä—ã –∏ –≤–∏–¥–µ–æ, –∞ —Ç–∞–∫–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ORB-–¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ `params`.\n",
    "\n",
    "        :param video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, .mp4)\n",
    "        :param calibration_file: –ø—É—Ç—å –∫ YAML-—Ñ–∞–π–ª—É —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π (—Ñ–æ—Ä–º–∞—Ç OpenCV / ROS)\n",
    "        :param target_fps: —á–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤\n",
    "        :param params: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–µ –≤ ORB.create(), –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
    "                       nfeatures=3000, edgeThreshold=10, fastThreshold=5 –∏ —Ç.–ø.\n",
    "        \"\"\"\n",
    "        self.params: dict = params\n",
    "        self.video_path = Path(video_path)\n",
    "        self.calibration_file = Path(calibration_file)\n",
    "        self.target_fps = self.params.get(\"target_fps\", 2)\n",
    "        \n",
    "        self.K: np.ndarray \n",
    "        self.distCoeffs: Optional[np.ndarray]\n",
    "        self.distortion_model: Optional[str]\n",
    "\n",
    "        self.K, self.distCoeffs, self.distortion_model = self.load_calibration(self.calibration_file)\n",
    "        self.frames: List[np.ndarray] = self.load_frames(self.video_path)\n",
    "        \n",
    "        self.keypoints: List = []  \n",
    "        self.matches: List = []   \n",
    "        self.keyframes: List[KeyFrame] = []\n",
    "        self.mappoints: List[MapPoint] = []\n",
    "        self.triangulated_points: List[np.ndarray] = []  \n",
    "        self.poses: List[np.ndarray] = []             \n",
    "\n",
    "        self.orb = self.create_orb()\n",
    "        self.matcher = self.create_matcher()\n",
    "        \n",
    "    def load_calibration(self, path: Union[str, Path]) -> Tuple[np.ndarray, Optional[np.ndarray], Optional[str]]:\n",
    "        \"\"\"\n",
    "        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏:\n",
    "        - –ï—Å–ª–∏ .txt ‚Üí KITTI —Ñ–æ—Ä–º–∞—Ç (—Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º P0: –∏–ª–∏ –±–µ–∑)\n",
    "        - –ï—Å–ª–∏ .yaml ‚Üí OpenCV / ROS\n",
    "        \"\"\"\n",
    "        path = Path(path)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"–§–∞–π–ª –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {path.resolve()}\")\n",
    "\n",
    "        if path.suffix == \".txt\":\n",
    "            with path.open(\"r\") as f:\n",
    "                lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ —Å P0:/P1:\n",
    "            for line in lines:\n",
    "                if line.startswith(\"P0:\") or line.startswith(\"P1:\"):\n",
    "                    values = list(map(float, line.split()[1:]))\n",
    "                    if len(values) == 12:\n",
    "                        P = np.array(values).reshape(3, 4)\n",
    "                        return P[:, :3], None, \"none\"\n",
    "\n",
    "            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ 12 —á–∏—Å–µ–ª\n",
    "            for line in lines:\n",
    "                values = list(map(float, line.split()))\n",
    "                if len(values) == 12:\n",
    "                    P = np.array(values).reshape(3, 4)\n",
    "                    return P[:, :3], None, \"none\"\n",
    "\n",
    "            raise ValueError(\"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç KITTI-—Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞ –∏–∑ 12 —á–∏—Å–µ–ª.\")\n",
    "\n",
    "        elif path.suffix in (\".yaml\", \".yml\"):\n",
    "            import yaml\n",
    "            with path.open('r') as f:\n",
    "                data = yaml.safe_load(f)\n",
    "\n",
    "            K_data = data[\"camera_matrix\"][\"data\"]\n",
    "            K = np.array(K_data, dtype=np.float64).reshape(3, 3)\n",
    "\n",
    "            dist_data = data.get(\"distortion_coefficients\", {}).get(\"data\", [])\n",
    "            distCoeffs = np.array(dist_data, dtype=np.float64) if dist_data else None\n",
    "\n",
    "            model = data.get(\"distortion_model\", None)\n",
    "            return K, distCoeffs, model\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {path}\") \n",
    "\n",
    "    def load_frames(self, path: Union[str, Path]) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–¥—Ä–æ–≤:\n",
    "        - –µ—Å–ª–∏ –ø—É—Ç—å ‚Äî –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, —Ç–æ PNG (KITTI)\n",
    "        - –µ—Å–ª–∏ —Ñ–∞–π–ª ‚Äî —Ç–æ –≤–∏–¥–µ–æ —Å –∑–∞–¥–∞–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π\n",
    "        –í—Å–µ –∫–∞–¥—Ä—ã –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –æ—Ç—Ç–µ–Ω–∫–∞–º —Å–µ—Ä–æ–≥–æ.\n",
    "        \"\"\"\n",
    "        path = Path(path)\n",
    "        frames = []\n",
    "\n",
    "        if path.is_dir():\n",
    "            # KITTI-–ø–æ–¥–æ–±–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "            image_paths = sorted(path.glob(\"*.png\"))\n",
    "            if not image_paths:\n",
    "                raise FileNotFoundError(f\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {path.resolve()}\")\n",
    "\n",
    "            for p in image_paths:\n",
    "                img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    frames.append(img)\n",
    "\n",
    "            print(f\"[KITTI] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤ –∏–∑ {path.name}\")\n",
    "\n",
    "        else:\n",
    "            # –í–∏–¥–µ–æ—Ñ–∞–π–ª\n",
    "            if not path.exists():\n",
    "                raise FileNotFoundError(f\"–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {path.resolve()}\")\n",
    "\n",
    "            cap = cv2.VideoCapture(str(path))\n",
    "            if not cap.isOpened():\n",
    "                raise IOError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {path}\")\n",
    "\n",
    "            video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_interval = max(1, int(video_fps / self.target_fps)) if video_fps else 1\n",
    "\n",
    "            print(f\"[–í–∏–¥–µ–æ] –ò–º—è: {path.name}\")\n",
    "            print(f\"- FPS: {video_fps:.2f}, –∫–∞–¥—Ä—ã: {total_frames}, –∏–Ω—Ç–µ—Ä–≤–∞–ª: {frame_interval}\")\n",
    "\n",
    "            frame_idx = 0\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if frame_idx % frame_interval == 0:\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    frames.append(gray)\n",
    "                frame_idx += 1\n",
    "\n",
    "            cap.release()\n",
    "            print(f\"[–í–∏–¥–µ–æ] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤ —Å —à–∞–≥–æ–º {frame_interval}\")\n",
    "\n",
    "        if not frames:\n",
    "            raise RuntimeError(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞.\")\n",
    "        return frames\n",
    "\n",
    "    def clear_data(self):\n",
    "        \"\"\"\n",
    "        –û—á–∏—â–∞–µ—Ç –≤—Å–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å–ø–∏—Å–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ.\n",
    "        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
    "        \"\"\"\n",
    "        self.keypoints.clear()\n",
    "        self.matches.clear()\n",
    "        self.keyframes.clear()\n",
    "        self.mappoints.clear()\n",
    "        self.poses.clear()\n",
    "        self.triangulated_points.clear()\n",
    "\n",
    "    # def create_matcher(self) -> cv2.DescriptorMatcher:\n",
    "    #     \"\"\"\n",
    "    #     –°–æ–∑–¥–∞—ë—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Ç—á–µ—Ä –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ –¥–ª—è ORB.\n",
    "    #     :return: –æ–±—ä–µ–∫—Ç cv2.DescriptorMatcher\n",
    "    #     \"\"\"\n",
    "    #     FLANN_INDEX_LSH = 6\n",
    "    #     index_params = dict(\n",
    "    #         algorithm=FLANN_INDEX_LSH,\n",
    "    #         table_number=self.params.get(\"flann_table_number\", 6),\n",
    "    #         key_size=self.params.get(\"flann_key_size\", 12), \n",
    "    #         multi_probe_level=self.params.get(\"flann_multi_probe_level\", 1)\n",
    "    #     )\n",
    "    #     search_params = dict(\n",
    "    #         checks=self.params.get(\"flann_checks\", 50)\n",
    "    #     )\n",
    "    #     return cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    def create_matcher(self):\n",
    "        return cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    \n",
    "    def create_orb(self) -> cv2.ORB:\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞—ë—Ç ORB-–¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞.\n",
    "        :return: –æ–±—ä–µ–∫—Ç cv2.ORB\n",
    "        \"\"\"\n",
    "        orb_params = {\n",
    "            \"nfeatures\": self.params.get(\"nfeatures\", 1000),\n",
    "            \"scaleFactor\": self.params.get(\"scaleFactor\", 1.2),\n",
    "            \"nlevels\": self.params.get(\"nlevels\", 8),\n",
    "            \"edgeThreshold\": self.params.get(\"edgeThreshold\", 31),\n",
    "            \"fastThreshold\": self.params.get(\"fastThreshold\", 20)\n",
    "        }\n",
    "        return cv2.ORB.create(**orb_params)\n",
    "    \n",
    "    def detect_and_compute(self, image: np.ndarray) -> Tuple[List[cv2.KeyPoint], np.ndarray]:\n",
    "        use_grid = self.params.get(\"use_grid\", False)\n",
    "\n",
    "        if not use_grid:\n",
    "            return self.orb.detectAndCompute(image, None)\n",
    "\n",
    "        num_rows = self.params.get(\"grid_rows\", 8)\n",
    "        num_cols = self.params.get(\"grid_cols\", 8)\n",
    "\n",
    "        h, w = image.shape\n",
    "        kp_all, des_all = [], []\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                x0 = int(j * w / num_cols)\n",
    "                x1 = int((j + 1) * w / num_cols)\n",
    "                y0 = int(i * h / num_rows)\n",
    "                y1 = int((i + 1) * h / num_rows)\n",
    "\n",
    "                roi = image[y0:y1, x0:x1]\n",
    "                kp, des = self.orb.detectAndCompute(roi, None)\n",
    "\n",
    "                for k in kp:\n",
    "                    k.pt = (k.pt[0] + x0, k.pt[1] + y0)\n",
    "\n",
    "                if kp:\n",
    "                    kp_all.extend(kp)\n",
    "                    if des is not None:\n",
    "                        des_all.append(des)\n",
    "\n",
    "        if des_all:\n",
    "            des_all = np.vstack(des_all)\n",
    "        else:\n",
    "            des_all = None\n",
    "        print(f\"[Debug] –ù–∞–π–¥–µ–Ω–æ {len(kp_all)} –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫\")\n",
    "        return kp_all, des_all\n",
    "    \n",
    "    def add_keyframe(self, frame_id: int, image: np.ndarray, keypoints, descriptors, pose: np.ndarray):\n",
    "        kf = KeyFrame(frame_id, image, keypoints, descriptors, pose)\n",
    "        self.keyframes.append(kf)\n",
    "\n",
    "    def add_mappoint(self, coord_3d: np.ndarray, frame_id: int, kp_idx: int, pt2d: Tuple[float, float], descriptor: np.ndarray):\n",
    "        mp = MapPoint(coord_3d, descriptor)\n",
    "        mp.observations.append((frame_id, kp_idx, pt2d))\n",
    "        self.mappoints.append(mp)\n",
    "           \n",
    "    def get_matches(\n",
    "        self,\n",
    "        kp1: List[cv2.KeyPoint],\n",
    "        des1: np.ndarray,\n",
    "        kp2: List[cv2.KeyPoint],\n",
    "        des2: np.ndarray\n",
    "    ) -> Tuple[List[cv2.KeyPoint], List[cv2.KeyPoint], List[cv2.DMatch], np.ndarray, np.ndarray]:\n",
    "\n",
    "        if des1 is None or des2 is None or len(kp1) == 0 or len(kp2) == 0:\n",
    "            return [], [], [], np.array([]), np.array([])\n",
    "\n",
    "        # 1. –ü–µ—Ä–≤–∏—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤\n",
    "        knn_matches = self.matcher.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # 2. Lowe's ratio test\n",
    "        ratio_thresh = self.params.get(\"ratio_thresh\", 0.6)\n",
    "        good_matches, pts1, pts2 = self.filter_by_ratio_test(knn_matches, kp1, kp2, ratio_thresh)\n",
    "\n",
    "        # 3. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏\n",
    "        max_dist = self.params.get(\"max_match_distance\", 60)\n",
    "        good_matches, pts1, pts2 = self.filter_by_max_distance(good_matches, pts1, pts2, max_dist)\n",
    "\n",
    "        # 4. –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è trainIdx\n",
    "        good_matches, pts1, pts2 = self.filter_unique_matches(good_matches, pts1, pts2)\n",
    "\n",
    "        # 5. –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É\n",
    "        good_matches, pts1, pts2 = self.filter_by_ransac_fundamental(good_matches, pts1, pts2)\n",
    "\n",
    "        # # 6. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ –∑–æ–Ω–∞–º –º–∞—Å–∫–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)\n",
    "        # mask_exclude_regions = self.params.get(\"mask_exclude_regions\", [])\n",
    "        # good_matches, pts1, pts2 = self.filter_by_exclusion_mask(good_matches, pts1, pts2, mask_exclude_regions)\n",
    "\n",
    "        # # 7. –í–∑–∞–∏–º–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è A‚ÜíB –∏ B‚ÜíA\n",
    "        # if self.params.get(\"use_mutual_check\", False):\n",
    "        #     good_matches, pts1, pts2 = self.filter_mutual_matches(\n",
    "        #         des1, des2, kp1, kp2, good_matches, pts1, pts2\n",
    "        #     )\n",
    "        \n",
    "        self.keypoints.append((kp1, kp2))\n",
    "        self.matches.append(good_matches)\n",
    "\n",
    "        return kp1, kp2, good_matches, pts1, pts2\n",
    "    \n",
    "    def estimate_pose_opencv(self, pts1: np.ndarray, pts2: np.ndarray) -> Optional[Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–≤–∏–∂–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ OpenCV.\n",
    "\n",
    "        :param pts1: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫ –≤ –ø–µ—Ä–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (Nx2)\n",
    "        :param pts2: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫ –≤–æ –≤—Ç–æ—Ä–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (Nx2)\n",
    "        :return: –∫–æ—Ä—Ç–µ–∂ (R, t) ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞ –∏ –≤–µ–∫—Ç–æ—Ä —Å–º–µ—â–µ–Ω–∏—è; –ª–∏–±–æ None –ø—Ä–∏ –æ—à–∏–±–∫–µ\n",
    "        \"\"\"\n",
    "        if pts1.shape[0] < 8 or pts2.shape[0] < 8:\n",
    "            print(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–≤–∏–∂–µ–Ω–∏—è.\")\n",
    "            return None\n",
    "        E, mask = cv2.findEssentialMat(\n",
    "            pts1, pts2, self.K, \n",
    "            method=cv2.RANSAC, \n",
    "            prob=0.999, \n",
    "            threshold=1.0\n",
    "        )\n",
    "        if E is None or mask is None or mask.sum() < 8:\n",
    "            print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É Essential.\")\n",
    "            return None\n",
    "        _, R, t, pose_mask = cv2.recoverPose(E, pts1, pts2, self.K, mask=mask)\n",
    "        \n",
    "        t = t / np.linalg.norm(t)\n",
    "        \n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t.ravel()\n",
    "        return T\n",
    "    \n",
    "    @staticmethod\n",
    "    def _form_transformation_matrix(R: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        –§–æ—Ä–º–∏—Ä—É–µ—Ç 4√ó4 –æ–¥–Ω–æ—Ä–æ–¥–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ R –∏ t.\n",
    "\n",
    "        :param R: –º–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞ 3√ó3\n",
    "        :param t: –≤–µ–∫—Ç–æ—Ä —Å–º–µ—â–µ–Ω–∏—è (3,)\n",
    "        :return: 4√ó4 –º–∞—Ç—Ä–∏—Ü–∞ T\n",
    "        \"\"\"\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "\n",
    "    def decompose_essential_custom(self, E: np.ndarray, q1: np.ndarray, q2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        –î–µ–∫–æ–º–ø–æ–∑–∏—Ä—É–µ—Ç Essential-–º–∞—Ç—Ä–∏—Ü—É, –≤—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞—Ä—É (R, t),\n",
    "        –ø—Ä–æ–≤–µ—Ä—è—è, —Å–∫–æ–ª—å–∫–æ —Ç–æ—á–µ–∫ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –ø–µ—Ä–µ–¥ –∫–∞–º–µ—Ä–∞–º–∏ (cheirality check).\n",
    "        –¢–∞–∫–∂–µ –≤—ã—á–∏—Å–ª—è–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–±.\n",
    "\n",
    "        :param E: –º–∞—Ç—Ä–∏—Ü–∞ Essential (3√ó3)\n",
    "        :param q1: —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ –∫–∞–¥—Ä–µ i-1\n",
    "        :param q2: —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –≤ –∫–∞–¥—Ä–µ i\n",
    "        :return: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ (R, t)\n",
    "        \"\"\"\n",
    "\n",
    "        def triangulate_and_score(R, t):\n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º 4√ó4 —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "            T = self._form_transformation_matrix(R, t)\n",
    "\n",
    "            # –ö–∞–º–µ—Ä–∞ 1: [K | 0], –ö–∞–º–µ—Ä–∞ 2: K * [R | t]\n",
    "            P0 = self.K @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "            P1 = self.K @ T[:3, :]\n",
    "\n",
    "            # –¢—Ä–∏–∞–Ω–≥—É–ª—è—Ü–∏—è\n",
    "            points_4d_hom = cv2.triangulatePoints(P0, P1, q1.T, q2.T)  # 4√óN\n",
    "            points_3d_1 = points_4d_hom[:3, :] / points_4d_hom[3, :]\n",
    "\n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–æ—á–∫–∏ –≤ —Å–∏—Å—Ç–µ–º—É –≤—Ç–æ—Ä–æ–π –∫–∞–º–µ—Ä—ã\n",
    "            points_4d_cam2 = T @ points_4d_hom\n",
    "            points_3d_2 = points_4d_cam2[:3, :] / points_4d_cam2[3, :]\n",
    "\n",
    "            # cheirality: —Å–∫–æ–ª—å–∫–æ —Ç–æ—á–µ–∫ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º z –≤ –æ–±–µ–∏—Ö –∫–∞–º–µ—Ä–∞—Ö\n",
    "            z1 = points_3d_1[2, :] > 0\n",
    "            z2 = points_3d_2[2, :] > 0\n",
    "            valid = z1 & z2\n",
    "            num_valid = np.sum(valid)\n",
    "\n",
    "            # –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–± (–ø–æ –¥–ª–∏–Ω–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ç–æ—á–∫–∞–º–∏)\n",
    "            if np.sum(valid) >= 2:\n",
    "                dist1 = np.linalg.norm(np.diff(points_3d_1.T[valid], axis=0), axis=1)\n",
    "                dist2 = np.linalg.norm(np.diff(points_3d_2.T[valid], axis=0), axis=1)\n",
    "                scale = np.mean(dist1 / dist2)\n",
    "            else:\n",
    "                scale = 1.0  # fallback\n",
    "\n",
    "            return num_valid, scale\n",
    "\n",
    "        # –ü–æ–ª—É—á–∞–µ–º 4 –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ä—ã R, t\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        t = np.squeeze(t)\n",
    "        candidates = [(R1,  t), (R1, -t), (R2,  t), (R2, -t)]\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∏ –≤—ã–±–∏—Ä–∞–µ–º —Ç—É, –≥–¥–µ –±–æ–ª—å—à–µ —Ç–æ—á–µ–∫ —Å–ø—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞–Ω—ã –≤–ø–µ—Ä–µ–¥\n",
    "        scores = []\n",
    "        scales = []\n",
    "        for R, t_candidate in candidates:\n",
    "            score, scale = triangulate_and_score(R, t_candidate)\n",
    "            scores.append(score)\n",
    "            scales.append(scale)\n",
    "\n",
    "        best_idx = np.argmax(scores)\n",
    "        best_R, best_t = candidates[best_idx]\n",
    "        best_scale = scales[best_idx]\n",
    "\n",
    "        # –ü—Ä–∏–º–µ–Ω–∏–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–±\n",
    "        t = best_t * best_scale\n",
    "\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞\n",
    "        desired_scale = 1\n",
    "        t = t / np.linalg.norm(t) * desired_scale\n",
    "        return best_R, t\n",
    "    \n",
    "    def estimate_pose_custom(self, pts1: np.ndarray, pts2: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é (R, t) –º–µ–∂–¥—É –¥–≤—É–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤—Ä—É—á–Ω—É—é:\n",
    "        - –∏–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É Essential;\n",
    "        - –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—é;\n",
    "        - —Å—Ç—Ä–æ–∏—Ç 4√ó4 –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "        :param pts1: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –Ω–∞ –∫–∞–¥—Ä–µ i-1 (Nx2)\n",
    "        :param pts2: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –Ω–∞ –∫–∞–¥—Ä–µ i   (Nx2)\n",
    "        :return: 4√ó4 –º–∞—Ç—Ä–∏—Ü–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–∏–ª–∏ None –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ)\n",
    "        \"\"\"\n",
    "        if pts1.shape[0] < 8 or pts2.shape[0] < 8:\n",
    "            print(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã Essential.\")\n",
    "            return None\n",
    "\n",
    "        E, mask = cv2.findEssentialMat(pts1, pts2, self.K, method=cv2.RANSAC, threshold=1.0, prob=0.999)\n",
    "        if E is None:\n",
    "            print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–∞—Ç—Ä–∏—Ü—É Essential.\")\n",
    "            return None\n",
    "\n",
    "        R, t = self.decompose_essential_custom(E, pts1, pts2)\n",
    "        T = self._form_transformation_matrix(R, np.squeeze(t))\n",
    "        return T\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_pointcloud(points: np.ndarray,\n",
    "                        z_min: float = 0.1,\n",
    "                        z_max: float = 10.0,\n",
    "                        x_range: Optional[Tuple[float, float]] = None,\n",
    "                        y_range: Optional[Tuple[float, float]] = None,\n",
    "                        voxel_size: Optional[float] = 0.05,\n",
    "                        apply_statistical: bool = True,\n",
    "                        nb_neighbors: int = 20,\n",
    "                        std_ratio: float = 2.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        –§–∏–ª—å—Ç—Ä—É–µ—Ç –æ–±–ª–∞–∫–æ —Ç–æ—á–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.\n",
    "\n",
    "        :param points: –ú–∞—Å—Å–∏–≤ 3D-—Ç–æ—á–µ–∫ —Ñ–æ—Ä–º—ã (N, 3)\n",
    "        \n",
    "        :param z_min: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã Z. –£–¥–∞–ª—è—é—Ç—Å—è —Ç–æ—á–∫–∏ –±–ª–∏–∂–µ, —á–µ–º z_min.\n",
    "        :param z_max: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è –≥–ª—É–±–∏–Ω–∞ Z. –£–¥–∞–ª—è—é—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–∞–ª—å–Ω–∏–µ —Ç–æ—á–∫–∏.\n",
    "        \n",
    "        :param x_range: –ö–æ—Ä—Ç–µ–∂ (min_x, max_x), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã X. –ï—Å–ª–∏ None ‚Äî –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç—Å—è.\n",
    "        :param y_range: –ö–æ—Ä—Ç–µ–∂ (min_y, max_y), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–∏–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã Y. –ï—Å–ª–∏ None ‚Äî –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç—Å—è.\n",
    "        \n",
    "        :param voxel_size: –†–∞–∑–º–µ—Ä —è—á–µ–π–∫–∏ –≤ voxel grid —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏. –ï—Å–ª–∏ None ‚Äî voxel-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è.\n",
    "                        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –∏ —Ä–∞–∑—Ä–µ–∂–∏–≤–∞–Ω–∏—è —Ç–æ—á–µ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.1 = 5 —Å–º).\n",
    "        \n",
    "        :param nb_neighbors: –ß–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏).\n",
    "        :param std_ratio: –ü–æ—Ä–æ–≥ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ ‚Äî —Ç–æ—á–∫–∏, —á—å—è —Å—Ä–µ–¥–Ω—è—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è –Ω–∞ std_ratio,\n",
    "                        –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã.\n",
    "        \n",
    "        :return: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–ª–∞–∫–æ —Ç–æ—á–µ–∫ (M, 3)\n",
    "        \"\"\"\n",
    "        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≥–ª—É–±–∏–Ω–µ –∏ NaN/Inf\n",
    "        mask = (points[:, 2] > z_min) & (points[:, 2] < z_max)\n",
    "        mask &= np.isfinite(points).all(axis=1)\n",
    "\n",
    "        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ X, Y (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã)\n",
    "        if x_range:\n",
    "            mask &= (points[:, 0] > x_range[0]) & (points[:, 0] < x_range[1])\n",
    "        if y_range:\n",
    "            mask &= (points[:, 1] > y_range[0]) & (points[:, 1] < y_range[1])\n",
    "\n",
    "        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞—Å–∫–∏\n",
    "        points = points[mask]\n",
    "        if len(points) == 0:\n",
    "            return points\n",
    "\n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç Open3D\n",
    "        import open3d as o3d\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "        # Voxel Grid ‚Äî —É–ø—Ä–æ—â–µ–Ω–∏–µ\n",
    "        if voxel_size:\n",
    "            pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "        if apply_statistical:\n",
    "            pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "\n",
    "        return np.asarray(pcd.points)\n",
    "\n",
    "    def triangulate_points(self,\n",
    "                        pts1: np.ndarray,\n",
    "                        pts2: np.ndarray,\n",
    "                        T1: np.ndarray,\n",
    "                        T2: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∏–∞–Ω–≥—É–ª—è—Ü–∏—é 3D-—Ç–æ—á–µ–∫ –∏–∑ –ø–∞—Ä—ã –∫–∞–¥—Ä–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—á–∫–∏ –≤ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç.\n",
    "\n",
    "        :param pts1: —Ç–æ—á–∫–∏ –≤ –ø–µ—Ä–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (Nx2)\n",
    "        :param pts2: —Ç–æ—á–∫–∏ –≤–æ –≤—Ç–æ—Ä–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (Nx2)\n",
    "        :param T1: –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–æ–∑–∞ –ø–µ—Ä–≤–æ–π –∫–∞–º–µ—Ä—ã (4√ó4)\n",
    "        :param T2: –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–æ–∑–∞ –≤—Ç–æ—Ä–æ–π –∫–∞–º–µ—Ä—ã (4√ó4)\n",
    "        :return: –º–∞—Å—Å–∏–≤ 3D-—Ç–æ—á–µ–∫ –≤ –º–∏—Ä–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ (M√ó3), –∏–ª–∏ None\n",
    "        \"\"\"\n",
    "        if pts1.shape[0] < 8 or pts2.shape[0] < 8:\n",
    "            return None\n",
    "\n",
    "        P1 = self.K @ T1[:3, :]\n",
    "        P2 = self.K @ T2[:3, :]\n",
    "\n",
    "\n",
    "        points_4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)  # 4√óN\n",
    "        points_3d = points_4d[:3, :] / points_4d[3, :]             # 3√óN ‚Üí –¥–µ–∫–∞—Ä—Ç–æ–≤—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã\n",
    "        points_3d = points_3d.T                                     # N√ó3\n",
    "\n",
    "        filtered_points = self.filter_pointcloud(\n",
    "            points_3d,\n",
    "            z_min=0.01,\n",
    "            z_max=200.0,\n",
    "            voxel_size=None,\n",
    "            apply_statistical=True\n",
    "        )\n",
    "\n",
    "        return filtered_points if len(filtered_points) > 0 else None\n",
    "    \n",
    "    def visualize_matches(self, delay_ms: int = 1000):\n",
    "        num_pairs = len(self.keypoints)\n",
    "        if num_pairs == 0:\n",
    "            print(\"–ù–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏ run().\")\n",
    "            return\n",
    "\n",
    "        print(\"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: [A] –Ω–∞–∑–∞–¥, [D] –≤–ø–µ—Ä—ë–¥, [Q] –≤—ã—Ö–æ–¥\")\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            kp1, kp2 = self.keypoints[i]\n",
    "            matches = self.matches[i]\n",
    "            img1 = self.frames[i]\n",
    "            img2 = self.frames[i + 1]\n",
    "\n",
    "            img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "            img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            vis = cv2.drawMatches(\n",
    "                img1_color, kp1,\n",
    "                img2_color, kp2,\n",
    "                matches, None,\n",
    "                matchColor=(0, 255, 0),\n",
    "                singlePointColor=(255, 0, 0),\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "\n",
    "            # –û—Ç—Ä–∏—Å–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π –∏–Ω–¥–µ–∫—Å\n",
    "            text = f\"Frame pair: {i} / {num_pairs - 1}\"\n",
    "            cv2.putText(vis, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Feature Matches (A/D/Q)\", vis)\n",
    "            key = cv2.waitKey(delay_ms) & 0xFF\n",
    "\n",
    "            if key == ord('q'):\n",
    "                print(\"–í—ã—Ö–æ–¥ –∏–∑ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\")\n",
    "                break\n",
    "            elif key == ord('d'):\n",
    "                i = min(i + 1, num_pairs - 1)\n",
    "            elif key == ord('a'):\n",
    "                i = max(i - 1, 0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def visualize_keypoints_pairwise(self, delay_ms: int = 0):\n",
    "        \"\"\"\n",
    "        –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä—ã –∫–∞–¥—Ä–æ–≤ —Å –Ω–∞–Ω–µ—Å—ë–Ω–Ω—ã–º–∏ ORB-—Ñ–∏—á–∞–º–∏ –±–µ–∑ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ª–∏–Ω–∏—è–º–∏.\n",
    "\n",
    "        –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:\n",
    "            [A] ‚Äî –Ω–∞–∑–∞–¥\n",
    "            [D] ‚Äî –≤–ø–µ—Ä—ë–¥\n",
    "            [Q] ‚Äî –≤—ã—Ö–æ–¥\n",
    "        \"\"\"\n",
    "        num_pairs = len(self.keypoints)\n",
    "        if num_pairs == 0:\n",
    "            print(\"–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏ run().\")\n",
    "            return\n",
    "\n",
    "        print(\"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: [A] –Ω–∞–∑–∞–¥, [D] –≤–ø–µ—Ä—ë–¥, [Q] –≤—ã—Ö–æ–¥\")\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            kp1, kp2 = self.keypoints[i]\n",
    "            img1 = self.frames[i]\n",
    "            img2 = self.frames[i + 1]\n",
    "\n",
    "            img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "            img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            vis1 = cv2.drawKeypoints(img1_color, kp1, None, color=(0, 255, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "            vis2 = cv2.drawKeypoints(img2_color, kp2, None, color=(255, 0, 0), flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "            vis = np.hstack((vis1, vis2))\n",
    "\n",
    "            # –ü–æ–¥–ø–∏—Å—å\n",
    "            text = f\"Frame pair: {i} / {num_pairs - 1}   Points: {len(kp1)} / {len(kp2)}\"\n",
    "            cv2.putText(vis, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Keypoints Only (A/D/Q)\", vis)\n",
    "            key = cv2.waitKey(delay_ms) & 0xFF\n",
    "\n",
    "            if key == ord('q'):\n",
    "                print(\"–í—ã—Ö–æ–¥ –∏–∑ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\")\n",
    "                break\n",
    "            elif key == ord('d'):\n",
    "                i = min(i + 1, num_pairs - 1)\n",
    "            elif key == ord('a'):\n",
    "                i = max(i - 1, 0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_first_valid_frame(self) -> Tuple[int, np.ndarray, List[cv2.KeyPoint], np.ndarray]:\n",
    "        for i, img in enumerate(self.frames):\n",
    "            kp, des = self.detect_and_compute(img)\n",
    "            if des is not None and len(kp) > 0:\n",
    "                return i, img, kp, des\n",
    "        raise RuntimeError(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏.\")\n",
    "    \n",
    "    def scale_translation_by_triangulation(self, R, t, pts1, pts2):\n",
    "        \"\"\"\n",
    "        –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä t, –∏—Å–ø–æ–ª—å–∑—É—è —Ç—Ä–∏–∞–Ω–≥—É–ª—è—Ü–∏—é —Ç–æ—á–µ–∫.\n",
    "        \"\"\"\n",
    "        T_temp = np.eye(4)\n",
    "        T_temp[:3, :3] = R\n",
    "        T_temp[:3, 3] = t.ravel()\n",
    "\n",
    "        X_world = self.triangulate_points(pts1, pts2, np.eye(4), T_temp)\n",
    "\n",
    "        if X_world is None or len(X_world) < 10:\n",
    "            print(\"[Scale] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–∞—Å—à—Ç–∞–±–∞.\")\n",
    "            return t\n",
    "\n",
    "        depths = np.linalg.norm(X_world, axis=1)\n",
    "        median_depth = np.median(depths)\n",
    "\n",
    "        print(f\"[Scale] –ö–æ–ª-–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(X_world)}\")\n",
    "        print(f\"[Scale] –ì–ª—É–±–∏–Ω–∞ —Ç–æ—á–µ–∫: mean={depths.mean():.3f}, median={median_depth:.3f}, min={depths.min():.3f}, max={depths.max():.3f}\")\n",
    "        print(f\"[Scale] –ù–æ—Ä–º–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ t: {np.linalg.norm(t):.3f}\")\n",
    "\n",
    "        if median_depth > 1e-6:\n",
    "            scale_factor = 1.0 / median_depth\n",
    "            t_scaled = t * scale_factor\n",
    "            print(f\"[Scale] –ú–∞—Å—à—Ç–∞–± –ø—Ä–∏–º–µ–Ω—ë–Ω: factor={scale_factor:.3f}, –Ω–æ—Ä–º–∞ –Ω–æ–≤–æ–≥–æ t={np.linalg.norm(t_scaled):.3f}\")\n",
    "        else:\n",
    "            t_scaled = t\n",
    "            print(\"[Scale] –û—à–∏–±–∫–∞: median_depth —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞, –º–∞—Å—à—Ç–∞–± –Ω–µ –∏–∑–º–µ–Ω—ë–Ω\")\n",
    "\n",
    "        return t_scaled\n",
    "\n",
    "    def bundle_adjustment(self, last_frame_size: int = 2):\n",
    "        if len(self.keyframes) < 2 or len(self.mappoints) < 10:\n",
    "            print(\"[BA] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\")\n",
    "            return\n",
    "\n",
    "        recent_kfs = self.keyframes[-last_frame_size:]\n",
    "        print(f\"[BA] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è {len(recent_kfs)} KeyFrame\")\n",
    "\n",
    "        for kf in recent_kfs:\n",
    "            obj_points = []\n",
    "            img_points = []\n",
    "\n",
    "            for mp in self.mappoints:\n",
    "                for obs in mp.observations:\n",
    "                    if obs[0] == kf.id:\n",
    "                        obj_points.append(mp.coord)\n",
    "                        img_points.append(obs[2])\n",
    "\n",
    "            if len(obj_points) < 6:\n",
    "                print(f\"[BA] KeyFrame {kf.id}: –º–∞–ª–æ —Ç–æ—á–µ–∫ ({len(obj_points)})\")\n",
    "                continue\n",
    "\n",
    "            obj_points = np.array(obj_points, dtype=np.float64)\n",
    "            img_points = np.array(img_points, dtype=np.float64)\n",
    "\n",
    "            # –Ω–∞—á–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–∑ —Ç–µ–∫—É—â–µ–π –ø–æ–∑—ã\n",
    "            R_init = kf.pose[:3, :3]\n",
    "            t_init = kf.pose[:3, 3]\n",
    "            rvec_init, _ = cv2.Rodrigues(R_init)\n",
    "            tvec_init = t_init.reshape(-1, 1)\n",
    "\n",
    "            success, rvec, tvec = cv2.solvePnP(\n",
    "                obj_points,\n",
    "                img_points,\n",
    "                self.K,\n",
    "                None,\n",
    "                rvec_init,\n",
    "                tvec_init,\n",
    "                useExtrinsicGuess=True,\n",
    "                flags=cv2.SOLVEPNP_ITERATIVE\n",
    "            )\n",
    "\n",
    "            if success:\n",
    "                R_opt, _ = cv2.Rodrigues(rvec)\n",
    "                T_opt = np.eye(4)\n",
    "                T_opt[:3, :3] = R_opt\n",
    "                T_opt[:3, 3] = tvec.ravel()\n",
    "                kf.pose = T_opt\n",
    "                self.poses[kf.id] = T_opt\n",
    "\n",
    "                print(f\"[BA] KeyFrame {kf.id}: –ø–æ–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞\")\n",
    "            else:\n",
    "                print(f\"[BA] KeyFrame {kf.id}: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å\")\n",
    "        \n",
    "    def filter_mappoints_depth(\n",
    "        self,\n",
    "        z_min: float = 0.1,\n",
    "        z_max: float = 100.0,\n",
    "        x_range: tuple = None,\n",
    "        y_range: tuple = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        –£–¥–∞–ª—è–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–∏–µ/–¥–∞–ª—ë–∫–∏–µ MapPoints –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "        \"\"\"\n",
    "\n",
    "        before = len(self.mappoints)\n",
    "        filtered = []\n",
    "\n",
    "        for mp in self.mappoints:\n",
    "            coord = mp.coord\n",
    "\n",
    "            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf\n",
    "            if not np.isfinite(coord).all():\n",
    "                continue\n",
    "\n",
    "            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≥–ª—É–±–∏–Ω–µ\n",
    "            if coord[2] < z_min or coord[2] > z_max:\n",
    "                continue\n",
    "\n",
    "            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ X, Y (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã)\n",
    "            if x_range and not (x_range[0] <= coord[0] <= x_range[1]):\n",
    "                continue\n",
    "            if y_range and not (y_range[0] <= coord[1] <= y_range[1]):\n",
    "                continue\n",
    "\n",
    "            filtered.append(mp)\n",
    "\n",
    "        self.mappoints = filtered\n",
    "        after = len(self.mappoints)\n",
    "\n",
    "        print(f\"[Filter] MapPoints –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {before}, –ø–æ—Å–ª–µ: {after}\")\n",
    "        print(f\"[Filter] –£–¥–∞–ª–µ–Ω–æ {before - after} —Ç–æ—á–µ–∫\")\n",
    "    \n",
    "    def init_map(self):\n",
    "        print(\"[Init] –ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞—Ä—Ç—ã...\")\n",
    "\n",
    "        start_idx, img1, kp1, des1 = self.get_first_valid_frame()\n",
    "        print(f\"[Init] –ü–µ—Ä–≤—ã–π –∫–∞–¥—Ä: #{start_idx}, –Ω–∞–π–¥–µ–Ω–æ {len(kp1)} –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫.\")\n",
    "\n",
    "        T_1 = np.eye(4, dtype=np.float64)\n",
    "\n",
    "        for i in range(start_idx + 1, len(self.frames)):\n",
    "            img2 = self.frames[i]\n",
    "            kp2, des2 = self.detect_and_compute(img2)\n",
    "\n",
    "            if des2 is None or len(kp2) == 0:\n",
    "                print(f\"[Init:{i}] –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä.\")\n",
    "                continue\n",
    "\n",
    "            kp1, kp2, matches, pts1, pts2 = self.get_matches(kp1, des1, kp2, des2)\n",
    "            print(f\"[Init:{i}] –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(matches)} —Ñ–∏—á –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ {i - 1} –∏ {i}\")\n",
    "            if len(matches) < self.params.get(\"min_matches\", 50):\n",
    "                print(f\"[Init:{i}] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∏—Ö –º–∞—Ç—á–µ–π: {len(matches)}, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∫–∞–¥—Ä.\")\n",
    "                continue\n",
    "            \n",
    "            mean_parallax = np.mean(np.linalg.norm(pts1 - pts2, axis=1))   \n",
    "            print(f\"[Init:{i}] –°—Ä–µ–¥–Ω–∏–π –ø–∞—Ä–∞–ª–ª–∞–∫—Å: {mean_parallax:.2f}\")         \n",
    "            if mean_parallax < self.params.get(\"min_parallax\", 5.0):\n",
    "                print(f\"[Init:{i}] –ú–∞–ª—ã–π –ø–∞—Ä–∞–ª–ª–∞–∫—Å ({mean_parallax:.2f}) ‚Äì –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∫–∞–¥—Ä.\")\n",
    "                continue\n",
    "\n",
    "            T_2 = self.estimate_pose_opencv(pts1, pts2)           \n",
    "            if T_2 is None:\n",
    "                print(f\"[Init:{i}] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å –ø–æ–∑—É, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∫–∞–¥—Ä.\")\n",
    "                continue   \n",
    "            \n",
    "            R = T_2[:3, :3]\n",
    "            t = T_2[:3, 3]\n",
    "            # t = self.scale_translation_by_triangulation(R, t, pts1, pts2)\n",
    "            t = t / np.linalg.norm(t)\n",
    "            T_2[:3, 3] = t\n",
    "\n",
    "\n",
    "            X_world = self.triangulate_points(pts1, pts2, T_1, T_2)\n",
    "            if X_world is None or len(X_world) < 50:\n",
    "                print(f\"[Init:{i}] –¢—Ä–∏–∞–Ω–≥—É–ª—è—Ü–∏—è –Ω–µ –¥–∞–ª–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫.\")\n",
    "                continue\n",
    "\n",
    "            self.add_keyframe(start_idx, img1, kp1, des1, T_1)\n",
    "            self.add_keyframe(i, img2, kp2, des2, T_2)\n",
    "            print(f\"[Init:{i}] –î–æ–±–∞–≤–ª–µ–Ω—ã KeyFrame #{start_idx} –∏ #{i}\")\n",
    "\n",
    "            for j, p in enumerate(X_world):\n",
    "                desc = des2[matches[j].trainIdx]\n",
    "                self.add_mappoint(p, i, matches[j].trainIdx, tuple(pts2[j]), desc)\n",
    "\n",
    "            self.poses.append(T_1)\n",
    "            self.poses.append(T_2)\n",
    "\n",
    "            print(f\"[Init:{i}] C–º–µ—â–µ–Ω–∏–µ: {np.linalg.norm(t):.3f}\")\n",
    "            print(f\"[Init:{i}] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\")\n",
    "            print(f\"  KeyFrames: {len(self.keyframes)}\")\n",
    "            print(f\"  MapPoints: {len(self.mappoints)}\")\n",
    "            \n",
    "            self.bundle_adjustment()\n",
    "            \n",
    "            z_min = self.params.get(\"filter_z_min\", 0.1)\n",
    "            z_max = self.params.get(\"filter_z_max\", 150.0)\n",
    "            x_range = self.params.get(\"filter_x_range\", (-100, 100))\n",
    "            y_range = self.params.get(\"filter_y_range\", (-100, 100))\n",
    "\n",
    "            self.filter_mappoints_depth(\n",
    "                z_min=z_min,\n",
    "                z_max=z_max,\n",
    "                x_range=x_range,\n",
    "                y_range=y_range\n",
    "            )\n",
    "            \n",
    "            t0 = self.poses[0][:3, 3]\n",
    "            t1 = self.poses[1][:3, 3]\n",
    "\n",
    "            print(f\"[Init:{i}] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã 0: X={t0[0]:.3f} Y={t0[1]:.3f} Z={t0[2]:.3f}\")\n",
    "            print(f\"[Init:{i}] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã 1: X={t1[0]:.3f} Y={t1[1]:.3f} Z={t1[2]:.3f}\")\n",
    "            \n",
    "            return i, img2, kp2, des2\n",
    "\n",
    "        raise RuntimeError(\"[Init] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç—É.\")\n",
    "    \n",
    "    def select_mappoint_candidates(self, pose: np.ndarray, image_shape: Tuple[int, int]):\n",
    "        if pose is None:\n",
    "            if len(self.poses) == 0:\n",
    "                return []\n",
    "            pose = self.poses[-1]\n",
    "\n",
    "        h, w = image_shape\n",
    "        candidates = []\n",
    "\n",
    "        count_invalid = 0\n",
    "        count_behind = 0\n",
    "        count_outside = 0\n",
    "\n",
    "        print(f\"[select_mappoint_candidates] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã (t) = {pose[:3, 3]}\")\n",
    "        print(f\"[select_mappoint_candidates] –í—Å–µ–≥–æ MapPoints = {len(self.mappoints)}\")\n",
    "\n",
    "        # –ò–Ω–≤–µ—Ä—Å–∏—è pose (camera‚Üíworld -> world‚Üícamera)\n",
    "        pose_inv = np.linalg.inv(pose)\n",
    "        K = self.K\n",
    "\n",
    "        for i, mp in enumerate(self.mappoints):\n",
    "            if mp.descriptor is None or not np.all(np.isfinite(mp.coord)):\n",
    "                count_invalid += 1\n",
    "                continue\n",
    "\n",
    "            Pw_hom = np.append(mp.coord, 1.0)\n",
    "            Pc = pose_inv @ Pw_hom\n",
    "\n",
    "            if Pc[2] <= 0:\n",
    "                count_behind += 1\n",
    "                continue\n",
    "\n",
    "            u = K[0, 0] * (Pc[0] / Pc[2]) + K[0, 2]\n",
    "            v = K[1, 1] * (Pc[1] / Pc[2]) + K[1, 2]\n",
    "\n",
    "            if u < 0 or u >= w or v < 0 or v >= h:\n",
    "                count_outside += 1\n",
    "                continue\n",
    "\n",
    "            candidates.append((i, mp.descriptor))\n",
    "\n",
    "        print(f\"[select_mappoint_candidates] –ù–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã (NaN/–Ω–µ—Ç –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞): {count_invalid}\")\n",
    "        print(f\"[select_mappoint_candidates] –ó–∞ –∫–∞–º–µ—Ä–æ–π: {count_behind}\")\n",
    "        print(f\"[select_mappoint_candidates] –í–Ω–µ –∫–∞–¥—Ä–∞: {count_outside}\")\n",
    "        print(f\"[select_mappoint_candidates] –í—ã–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}\")\n",
    "\n",
    "        return candidates\n",
    "\n",
    "    def visualize_map_and_camera(self, pose):\n",
    "        import open3d as o3d\n",
    "        import numpy as np\n",
    "\n",
    "        if len(self.mappoints) == 0:\n",
    "            print(\"–ù–µ—Ç MapPoints –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\")\n",
    "            return\n",
    "\n",
    "        h, w = 720, 1280  # –ª–∏–±–æ –ø–æ–¥—Å—Ç–∞–≤—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã\n",
    "\n",
    "        points = []\n",
    "        colors = []\n",
    "\n",
    "        pose_inv = np.linalg.inv(pose)\n",
    "        K = self.K\n",
    "\n",
    "        for mp in self.mappoints:\n",
    "            if not np.all(np.isfinite(mp.coord)):\n",
    "                continue\n",
    "\n",
    "            Pw_hom = np.append(mp.coord, 1.0)\n",
    "            Pc = pose_inv @ Pw_hom\n",
    "\n",
    "            if Pc[2] > 0:\n",
    "                # –ü—Ä–æ–µ–∫—Ü–∏—è –≤ –ø–∏–∫—Å–µ–ª–∏\n",
    "                u = K[0, 0] * (Pc[0] / Pc[2]) + K[0, 2]\n",
    "                v = K[1, 1] * (Pc[1] / Pc[2]) + K[1, 2]\n",
    "                if 0 <= u < w and 0 <= v < h:\n",
    "                    color = [0, 1, 0]  # –∑–µ–ª—ë–Ω—ã–π (–≤ –∫–∞–¥—Ä–µ)\n",
    "                else:\n",
    "                    color = [1, 0, 0]  # –∫—Ä–∞—Å–Ω—ã–π (–≤–Ω–µ –∫–∞–¥—Ä–∞)\n",
    "            else:\n",
    "                color = [1, 0, 0]      # –∫—Ä–∞—Å–Ω—ã–π (–∑–∞ –∫–∞–º–µ—Ä–æ–π)\n",
    "\n",
    "            points.append(mp.coord)\n",
    "            colors.append(color)\n",
    "\n",
    "        points = np.array(points)\n",
    "        colors = np.array(colors)\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        frustum = self.create_camera_frustum(scale=5.0)\n",
    "        frustum.transform(pose)\n",
    "\n",
    "        cam_center = o3d.geometry.TriangleMesh.create_sphere(radius=0.2)\n",
    "        cam_center.translate(pose[:3, 3])\n",
    "        cam_center.paint_uniform_color([1, 0.7, 0])\n",
    "\n",
    "        o3d.visualization.draw_geometries([pcd, frustum, cam_center],\n",
    "                                        window_name=\"MapPoints and Camera\",\n",
    "                                        width=1280, height=720)\n",
    "        \n",
    "    def create_camera_frustum(self, scale: float = 0.05) -> o3d.geometry.LineSet:\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞—ë—Ç 3D-–º–æ–¥–µ–ª—å –ø–∏—Ä–∞–º–∏–¥—ã –∫–∞–º–µ—Ä—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ open3d.\n",
    "        scale ‚Äì –º–∞—Å—à—Ç–∞–± —Ñ—Ä—É—Å—Ç—É–º–∞\n",
    "        \"\"\"\n",
    "        points = np.array([\n",
    "            [0, 0, 0],\n",
    "            [ scale,  scale,  scale * 2],\n",
    "            [ scale, -scale,  scale * 2],\n",
    "            [-scale, -scale,  scale * 2],\n",
    "            [-scale,  scale,  scale * 2],\n",
    "        ])\n",
    "        lines = [\n",
    "            [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "            [1, 2], [2, 3], [3, 4], [4, 1]\n",
    "        ]\n",
    "        frustum = o3d.geometry.LineSet()\n",
    "        frustum.points = o3d.utility.Vector3dVector(points)\n",
    "        frustum.lines = o3d.utility.Vector2iVector(lines)\n",
    "        frustum.paint_uniform_color([0.0, 0.6, 1.0])\n",
    "        return frustum\n",
    "    \n",
    "    def track_frame(self, img, kp, des):\n",
    "\n",
    "        if len(self.mappoints) == 0 or des is None or len(kp) == 0:\n",
    "            print(\"[TrackFrame] –ù–µ—Ç MapPoints –∏–ª–∏ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤.\")\n",
    "            return None\n",
    "\n",
    "        # 1. –í—ã–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "        pose_guess = self.poses[-1] if len(self.poses) > 0 else np.eye(4)\n",
    "        pose = self.poses[-1]  # –∏–ª–∏ –Ω—É–∂–Ω—ã–π KeyFrame.pose\n",
    "        # self.visualize_map_and_camera(pose)\n",
    "        candidates = self.select_mappoint_candidates(pose_guess, img.shape)\n",
    "\n",
    "        if not candidates:\n",
    "            print(\"[TrackFrame] –ù–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞.\")\n",
    "            return None\n",
    "        \n",
    "        # 2. –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤\n",
    "        des_mps = np.array([desc for _, desc in candidates])\n",
    "        mp_indices = [idx for idx, _ in candidates]\n",
    "\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "        knn_matches = matcher.knnMatch(des_mps, des, k=2)\n",
    "\n",
    "        # Ratio test\n",
    "        ratio_thresh = self.params.get(\"ratio_thresh\", 0.6)\n",
    "        good_matches = []\n",
    "        matches_map = []\n",
    "\n",
    "        for pair in knn_matches:\n",
    "            if len(pair) < 2:\n",
    "                continue\n",
    "            m, n = pair\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                mp_index = mp_indices[m.queryIdx]\n",
    "                matches_map.append((mp_index, m.trainIdx))\n",
    "                good_matches.append(m)\n",
    "\n",
    "        print(f\"[TrackFrame] –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ—Å–ª–µ ratio test: {len(good_matches)}\")\n",
    "\n",
    "        # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä 3D‚Äì2D –¥–ª—è PnP\n",
    "        object_points = np.array([self.mappoints[mp_i].coord for mp_i, _ in matches_map])\n",
    "        image_points = np.array([kp[kp_i].pt for _, kp_i in matches_map])\n",
    "    \n",
    "        \n",
    "        if object_points.shape[0] < 4:\n",
    "            print(\"[TrackFrame] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è PnP.\")\n",
    "            return None\n",
    "\n",
    "        # 4. –†–µ—à–µ–Ω–∏–µ PnP\n",
    "        success, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
    "            object_points,\n",
    "            image_points,\n",
    "            self.K,\n",
    "            None,\n",
    "            iterationsCount=1000,\n",
    "            reprojectionError=8.0,\n",
    "            confidence=0.99\n",
    "        )\n",
    "\n",
    "        if not success or inliers is None or len(inliers) < 6:\n",
    "            print(\"[TrackFrame] PnP –Ω–µ —É–¥–∞–ª–æ—Å—å.\")\n",
    "            return None\n",
    "\n",
    "        # 5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–æ–∑—ã\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = tvec.ravel()\n",
    "\n",
    "        print(f\"[TrackFrame] PnP —É—Å–ø–µ—à–µ–Ω. Inliers: {len(inliers)}\")\n",
    "        print(f\"[TrackFrame] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã: X={T[0,3]:.3f} Y={T[1,3]:.3f} Z={T[2,3]:.3f}\")\n",
    "\n",
    "        # –î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ KeyFrame\n",
    "        pass\n",
    "    \n",
    "    def find_mappoint_for_keypoint(self, frame_id: int, kp_idx: int):\n",
    "        for mp in self.mappoints:\n",
    "            for obs in mp.observations:\n",
    "                if obs[0] == frame_id and obs[1] == kp_idx:\n",
    "                    return mp\n",
    "        return None\n",
    "    \n",
    "    def create_new_keyframe(self, frame_id, img, kp, des, pose):\n",
    "        print(f\"[KeyFrame] –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π KeyFrame #{frame_id}\")\n",
    "        self.add_keyframe(frame_id, img, kp, des, pose)\n",
    "\n",
    "        total_new_points = 0\n",
    "\n",
    "        for prev_kf in self.keyframes[-3:]:  # –∏—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 3 KeyFrames\n",
    "            kp1, kp2, matches, pts1, pts2 = self.get_matches(\n",
    "                prev_kf.keypoints, prev_kf.descriptors, kp, des\n",
    "            )\n",
    "\n",
    "            print(f\"[KeyFrame] –ú–∞—Ç—á–µ–π —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º KeyFrame #{prev_kf.id}: {len(matches)}\")\n",
    "\n",
    "            if len(matches) < 8:\n",
    "                continue\n",
    "\n",
    "            X_world = self.triangulate_points(pts1, pts2, prev_kf.pose, pose)\n",
    "            if X_world is None:\n",
    "                continue\n",
    "\n",
    "            added = 0\n",
    "            for j, p in enumerate(X_world):\n",
    "                kp_idx = matches[j].trainIdx\n",
    "\n",
    "                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–≤—è–∑–∞–Ω –ª–∏ —É–∂–µ —ç—Ç–æ—Ç keypoint —Å MapPoint\n",
    "                if self.find_mappoint_for_keypoint(frame_id, kp_idx) is not None:\n",
    "                    continue\n",
    "\n",
    "                desc = des[kp_idx]\n",
    "                self.add_mappoint(\n",
    "                    coord_3d=p,\n",
    "                    frame_id=frame_id,\n",
    "                    kp_idx=kp_idx,\n",
    "                    pt2d=tuple(pts2[j]),\n",
    "                    descriptor=desc\n",
    "                )\n",
    "                added += 1\n",
    "\n",
    "            total_new_points += added\n",
    "            print(f\"[KeyFrame] –î–æ–±–∞–≤–ª–µ–Ω–æ {added} –Ω–æ–≤—ã—Ö MapPoints –∏–∑ –ø–∞—Ä—ã —Å KeyFrame #{prev_kf.id}\")\n",
    "\n",
    "        print(f\"[KeyFrame] –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_new_points} –Ω–æ–≤—ã—Ö MapPoints –¥–ª—è KeyFrame #{frame_id}\")\n",
    "\n",
    "    def need_new_keyframe(self, T_curr: np.ndarray, keypoints: List[cv2.KeyPoint]) -> bool:\n",
    "        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ self.params\n",
    "        min_tracked = self.params.get(\"min_tracked_points\", 30)\n",
    "        min_interval = self.params.get(\"keyframe_interval\", 10)\n",
    "        translation_thresh = self.params.get(\"keyframe_translation_thresh\", 0.2)\n",
    "\n",
    "        if len(self.keyframes) == 0:\n",
    "            print(\"[KeyFrameDecision] –ù–µ—Ç KeyFrames ‚Äì –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π.\")\n",
    "            return True\n",
    "\n",
    "        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–∫–∞—é—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ\n",
    "        tracked_points = sum(\n",
    "            1\n",
    "            for mp in self.mappoints\n",
    "            for obs in mp.observations\n",
    "            if obs[0] == len(self.poses) - 1\n",
    "        )\n",
    "        print(f\"[KeyFrameDecision] –¢—Ä–µ–∫ —Ç–æ—á–µ–∫: {tracked_points}\")\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É KeyFrames\n",
    "        frames_since_last_kf = len(self.poses) - 1 - self.keyframes[-1].id\n",
    "        print(f\"[KeyFrameDecision] –ö–∞–¥—Ä–æ–≤ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ KeyFrame: {frames_since_last_kf}\")\n",
    "\n",
    "        if frames_since_last_kf < min_interval:\n",
    "            print(f\"[KeyFrameDecision] –ï—â—ë –Ω–µ –ø—Ä–æ—à–ª–æ {min_interval} –∫–∞–¥—Ä–æ–≤ ‚Äì KeyFrame –Ω–µ —Å–æ–∑–¥–∞—ë–º.\")\n",
    "            return False\n",
    "\n",
    "        # –ï—Å–ª–∏ —Ç—Ä–µ–∫–∞–µ—Ç—Å—è –º–∞–ª–æ —Ç–æ—á–µ–∫ ‚Äì –¥–æ–±–∞–≤–ª—è–µ–º KeyFrame\n",
    "        if tracked_points < min_tracked:\n",
    "            print(\"[KeyFrameDecision] –ú–∞–ª–æ —Ç–æ—á–µ–∫ ‚Äì –¥–æ–±–∞–≤–ª—è–µ–º KeyFrame.\")\n",
    "            return True\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã\n",
    "        last_kf_pose = self.keyframes[-1].pose\n",
    "        delta = np.linalg.norm(T_curr[:3, 3] - last_kf_pose[:3, 3])\n",
    "        print(f\"[KeyFrameDecision] –°–º–µ—â–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã: {delta:.3f}\")\n",
    "\n",
    "        if delta > translation_thresh:\n",
    "            print(\"[KeyFrameDecision] –ö–∞–º–µ—Ä–∞ —Å–∏–ª—å–Ω–æ —Å–º–µ—Å—Ç–∏–ª–∞—Å—å ‚Äì –¥–æ–±–∞–≤–ª—è–µ–º KeyFrame.\")\n",
    "            return True\n",
    "\n",
    "        print(\"[KeyFrameDecision] –ù–æ–≤—ã–π KeyFrame –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.\")\n",
    "        return False\n",
    "\n",
    "    def visualize_keypoints(self, img, kp, window_name=\"Keypoints\"):\n",
    "        img_vis = cv2.drawKeypoints(\n",
    "            img, kp, None,\n",
    "            color=(0, 255, 0),\n",
    "            flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        cv2.imshow(window_name, img_vis)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "\n",
    "        if len(self.frames) < 2:\n",
    "            raise ValueError(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–¥–æ–º–µ—Ç—Ä–∏–∏.\")\n",
    "        \n",
    "        idx, img1, kp1, des1 = self.init_map()\n",
    "\n",
    "        # for i in range(idx + 1, len(self.frames)):\n",
    "        for i in range(idx + 1, 4):\n",
    "            print(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ {i} –∏–∑ {len(self.frames)}...\")\n",
    "            img2 = self.frames[i]\n",
    "            kp2, des2 = self.detect_and_compute(img2)\n",
    "            \n",
    "            # self.visualize_keypoints(img2, kp2)\n",
    "\n",
    "            if des2 is None or len(kp2) == 0:\n",
    "                continue\n",
    "\n",
    "            # –¢—Ä–µ–∫–∏–Ω–≥ –ø–æ PnP\n",
    "            T_curr = self.track_frame(img2, kp2, des2)\n",
    "            \n",
    "            # if T_curr is None:\n",
    "            #     # fallback –Ω–∞ get_matches, –µ—Å–ª–∏ PnP –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª\n",
    "            #     kp1, kp2, matches, pts1, pts2 = self.get_matches(kp1, des1, kp2, des2)\n",
    "            #     if len(matches) >= 8:\n",
    "            #         T_curr = self.estimate_pose_custom(pts1, pts2)\n",
    "            #     else:\n",
    "            #         continue\n",
    "\n",
    "            # self.poses.append(T_curr)\n",
    "\n",
    "            # # –†–µ—à–µ–Ω–∏–µ –æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ KeyFrame\n",
    "            # if self.need_new_keyframe(T_curr, kp2):\n",
    "            #     self.create_new_keyframe(i, img2, kp2, des2, T_curr)\n",
    "\n",
    "            img1, kp1, des1 = img2, kp2, des2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "180ae125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KITTI] –ó–∞–≥—Ä—É–∂–µ–Ω–æ 51 –∫–∞–¥—Ä–æ–≤ –∏–∑ image_l\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "VIDEO_PATH = DATA_PATH / 'KITTI_sequence_1/image_l'\n",
    "CALIBRATION_PATH = DATA_PATH / 'KITTI_sequence_1/calib.txt'\n",
    "TARGET_FPS = 2.0\n",
    "\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise FileNotFoundError(f'–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {VIDEO_PATH.resolve()}')\n",
    "\n",
    "if not CALIBRATION_PATH.exists():\n",
    "    raise FileNotFoundError(f'–ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {CALIBRATION_PATH.resolve()}')\n",
    "\n",
    "params = {\n",
    "    \"target_fps\": TARGET_FPS,  # —á–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤\n",
    "    \n",
    "    # ORB-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    \"nfeatures\": 400,           # [default=500] –±–æ–ª—å—à–µ —Ñ–∏—á ‚Äî –≤—ã—à–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—Ä—ã—Ç–∏—è —Å—Ü–µ–Ω—ã\n",
    "    \"fastThreshold\":20,          # [default=20] –Ω–∏–∂–µ –ø–æ—Ä–æ–≥ ‚Äî —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–µ–µ –∫ —Å–ª–∞–±—ã–º —É–≥–ª–∞–º\n",
    "    \"edgeThreshold\": 5,         # [default=31] –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –±–ª–∏–∂–µ –∫ –∫—Ä–∞—è–º –∫–∞–¥—Ä–∞\n",
    "    \"scaleFactor\": 1.2,          # [default=1.2] –º–∞—Å—à—Ç–∞–± –º–µ–∂–¥—É —É—Ä–æ–≤–Ω—è–º–∏ –ø–∏—Ä–∞–º–∏–¥—ã (–º–µ–Ω—å—à–µ ‚Äî –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Ç–æ—á–Ω–µ–µ)\n",
    "    \"nlevels\": 8,               # [default=8] —á–∏—Å–ª–æ —É—Ä–æ–≤–Ω–µ–π –ø–∏—Ä–∞–º–∏–¥—ã ‚Äî –≤—ã—à–µ = –ª—É—á—à–µ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –º–∞—Å—à—Ç–∞–±—É\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–∞—Ç—á–µ–π –ø–æ –¥–∏—Å—Ç–∞–Ω—Ü–∏–∏ (Lowe‚Äôs ratio test)\n",
    "    \"ratio_thresh\": 0.5,         # [default=0.75] —Å—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –æ—Å—Ç–∞–≤–ª—è—Ç—å —Ç–æ–ª—å–∫–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è\n",
    "    \"max_match_distance\": 200,\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å–µ—Ç–∫–∏\n",
    "    \"use_grid\": True,       # –≤–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ —Å–µ—Ç–∫–∏\n",
    "    \"grid_rows\": 4,\n",
    "    \"grid_cols\": 6,\n",
    "\n",
    "    \"flann_table_number\": 10,\n",
    "    \"flann_key_size\": 14,\n",
    "    \"flann_multi_probe_level\": 2,\n",
    "    \"flann_checks\": 50\n",
    "}\n",
    "\n",
    "\n",
    "vo = VisualOdometry(\n",
    "    video_path=VIDEO_PATH,\n",
    "    calibration_file=CALIBRATION_PATH,\n",
    "    **params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4974ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, clear_output\n",
    "# from PIL import Image\n",
    "# import time\n",
    "# import cv2\n",
    "\n",
    "# num_frames_to_show = int(TARGET_FPS * 30)\n",
    "# frames_to_show = vo.frames[:num_frames_to_show]\n",
    "\n",
    "# for frame in frames_to_show:\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "#     clear_output(wait=True)\n",
    "#     display(Image.fromarray(rgb_frame))\n",
    "#     time.sleep(1 / TARGET_FPS / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60a1c192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] –ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞—Ä—Ç—ã...\n",
      "[Debug] –ù–∞–π–¥–µ–Ω–æ 6268 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫\n",
      "[Init] –ü–µ—Ä–≤—ã–π –∫–∞–¥—Ä: #0, –Ω–∞–π–¥–µ–Ω–æ 6268 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫.\n",
      "[Debug] –ù–∞–π–¥–µ–Ω–æ 6467 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫\n",
      "[Init:1] –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ 369 —Ñ–∏—á –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ 0 –∏ 1\n",
      "[Init:1] –°—Ä–µ–¥–Ω–∏–π –ø–∞—Ä–∞–ª–ª–∞–∫—Å: 7.08\n",
      "[Init:1] –î–æ–±–∞–≤–ª–µ–Ω—ã KeyFrame #0 –∏ #1\n",
      "[Init:1] C–º–µ—â–µ–Ω–∏–µ: 1.000\n",
      "[Init:1] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\n",
      "  KeyFrames: 2\n",
      "  MapPoints: 329\n",
      "[BA] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è 2 KeyFrame\n",
      "[BA] KeyFrame 0: –º–∞–ª–æ —Ç–æ—á–µ–∫ (0)\n",
      "[BA] KeyFrame 1: –ø–æ–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞\n",
      "[Filter] MapPoints –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: 329, –ø–æ—Å–ª–µ: 291\n",
      "[Filter] –£–¥–∞–ª–µ–Ω–æ 38 —Ç–æ—á–µ–∫\n",
      "[Init:1] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã 0: X=0.000 Y=0.000 Z=0.000\n",
      "[Init:1] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã 1: X=2.693 Y=-2.646 Z=23.300\n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ 2 –∏–∑ 51...\n",
      "[Debug] –ù–∞–π–¥–µ–Ω–æ 6368 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫\n",
      "[select_mappoint_candidates] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã (t) = [ 2.69262051 -2.64575406 23.3001648 ]\n",
      "[select_mappoint_candidates] –í—Å–µ–≥–æ MapPoints = 291\n",
      "[select_mappoint_candidates] –ù–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã (NaN/–Ω–µ—Ç –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞): 0\n",
      "[select_mappoint_candidates] –ó–∞ –∫–∞–º–µ—Ä–æ–π: 84\n",
      "[select_mappoint_candidates] –í–Ω–µ –∫–∞–¥—Ä–∞: 53\n",
      "[select_mappoint_candidates] –í—ã–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: 154\n",
      "[TrackFrame] –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ—Å–ª–µ ratio test: 61\n",
      "[TrackFrame] PnP —É—Å–ø–µ—à–µ–Ω. Inliers: 29\n",
      "[TrackFrame] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã: X=-0.225 Y=0.016 Z=-1.912\n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ 3 –∏–∑ 51...\n",
      "[Debug] –ù–∞–π–¥–µ–Ω–æ 5921 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫\n",
      "[select_mappoint_candidates] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã (t) = [ 2.69262051 -2.64575406 23.3001648 ]\n",
      "[select_mappoint_candidates] –í—Å–µ–≥–æ MapPoints = 291\n",
      "[select_mappoint_candidates] –ù–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã (NaN/–Ω–µ—Ç –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞): 0\n",
      "[select_mappoint_candidates] –ó–∞ –∫–∞–º–µ—Ä–æ–π: 84\n",
      "[select_mappoint_candidates] –í–Ω–µ –∫–∞–¥—Ä–∞: 53\n",
      "[select_mappoint_candidates] –í—ã–±—Ä–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: 154\n",
      "[TrackFrame] –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ—Å–ª–µ ratio test: 38\n",
      "[TrackFrame] PnP —É—Å–ø–µ—à–µ–Ω. Inliers: 20\n",
      "[TrackFrame] –ü–æ–∑–∞ –∫–∞–º–µ—Ä—ã: X=-0.061 Y=-1.665 Z=-1.727\n"
     ]
    }
   ],
   "source": [
    "vo.clear_data()\n",
    "vo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c3e7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vo.debug_check_coordinate_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22a03091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vo.visualize_keypoints_pairwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d7d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vo.visualize_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54acc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# def visualize_full_map(vo):\n",
    "#     if len(vo.mappoints) == 0:\n",
    "#         print(\"–ù–µ—Ç MapPoints –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")\n",
    "#         return\n",
    "\n",
    "#     # 1. –°–æ–∑–¥–∞—ë–º –æ–±–ª–∞–∫–æ —Ç–æ—á–µ–∫\n",
    "#     points = np.array([mp.coord for mp in vo.mappoints])\n",
    "#     pcd = o3d.geometry.PointCloud()\n",
    "#     pcd.points = o3d.utility.Vector3dVector(points)\n",
    "#     pcd.paint_uniform_color([1.0, 0.0, 0.0])  # –∫—Ä–∞—Å–Ω—ã–µ —Ç–æ—á–∫–∏\n",
    "\n",
    "#     # 2. –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ —Ñ—Ä—É—Å—Ç—É–º–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–æ–∑ –∫–∞–º–µ—Ä—ã\n",
    "#     frustums = []\n",
    "#     for i, pose in enumerate(vo.poses):\n",
    "#         frustum = vo.create_camera_frustum(scale=0.05)\n",
    "#         frustum.transform(pose)\n",
    "#         frustums.append(frustum)\n",
    "\n",
    "#     # 3. –°–æ–∑–¥–∞—ë–º –ª–∏–Ω–∏—é —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏\n",
    "#     trajectory_points = [pose[:3, 3] for pose in vo.poses]\n",
    "#     trajectory_lines = [[i, i+1] for i in range(len(trajectory_points)-1)]\n",
    "#     trajectory = o3d.geometry.LineSet()\n",
    "#     trajectory.points = o3d.utility.Vector3dVector(trajectory_points)\n",
    "#     trajectory.lines = o3d.utility.Vector2iVector(trajectory_lines)\n",
    "#     trajectory.paint_uniform_color([0.0, 1.0, 0.0])  # –∑–µ–ª—ë–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è\n",
    "\n",
    "#     # 4. –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤—Å—ë –≤–º–µ—Å—Ç–µ\n",
    "#     o3d.visualization.draw_geometries([pcd, trajectory, *frustums],\n",
    "#                                       window_name=\"–ü–æ–ª–Ω–∞—è –∫–∞—Ä—Ç–∞ –∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è\",\n",
    "#                                       width=1280, height=720)\n",
    "\n",
    "\n",
    "# visualize_full_map(vo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34a65a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def create_camera_frustum(scale: float = 0.05) -> o3d.geometry.LineSet:\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞—ë—Ç 3D-–º–æ–¥–µ–ª—å –ø–∏—Ä–∞–º–∏–¥—ã –∫–∞–º–µ—Ä—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ open3d.\n",
    "    scale ‚Äì –º–∞—Å—à—Ç–∞–± —Ñ—Ä—É—Å—Ç—É–º–∞\n",
    "    \"\"\"\n",
    "    points = np.array([\n",
    "        [0, 0, 0],\n",
    "        [ scale,  scale,  scale * 2],\n",
    "        [ scale, -scale,  scale * 2],\n",
    "        [-scale, -scale,  scale * 2],\n",
    "        [-scale,  scale,  scale * 2],\n",
    "    ])\n",
    "    lines = [\n",
    "        [0, 1], [0, 2], [0, 3], [0, 4],\n",
    "        [1, 2], [2, 3], [3, 4], [4, 1]\n",
    "    ]\n",
    "    frustum = o3d.geometry.LineSet()\n",
    "    frustum.points = o3d.utility.Vector3dVector(points)\n",
    "    frustum.lines = o3d.utility.Vector2iVector(lines)\n",
    "    frustum.paint_uniform_color([0.0, 0.6, 1.0])\n",
    "    return frustum\n",
    "\n",
    "\n",
    "def check_and_visualize_mappoints(vo):\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç 3D MapPoints –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "    vo: —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ VisualOdometry\n",
    "    \"\"\"\n",
    "    if not vo.mappoints:\n",
    "        print(\"[Check] –ù–µ—Ç MapPoints –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")\n",
    "        return\n",
    "\n",
    "    coords = np.array([mp.coord for mp in vo.mappoints if np.all(np.isfinite(mp.coord))])\n",
    "\n",
    "    if coords.size == 0:\n",
    "        print(\"[Check] –í—Å–µ —Ç–æ—á–∫–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã.\")\n",
    "        return\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    depths = coords[:, 2]\n",
    "    print(f\"[Check] –í—Å–µ–≥–æ —Ç–æ—á–µ–∫: {len(coords)}\")\n",
    "    print(f\"[Check] –ì–ª—É–±–∏–Ω–∞ Z: mean={depths.mean():.3f}, median={np.median(depths):.3f}, min={depths.min():.3f}, max={depths.max():.3f}\")\n",
    "\n",
    "    print(f\"[Check] X: mean={coords[:,0].mean():.3f}, min={coords[:,0].min():.3f}, max={coords[:,0].max():.3f}\")\n",
    "    print(f\"[Check] Y: mean={coords[:,1].mean():.3f}, min={coords[:,1].min():.3f}, max={coords[:,1].max():.3f}\")\n",
    "\n",
    "    print(\"[Check] –ü—Ä–∏–º–µ—Ä—ã —Ç–æ—á–µ–∫:\")\n",
    "    for i in range(min(5, len(coords))):\n",
    "        print(f\"   {coords[i]}\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º PointCloud –¥–ª—è Open3D\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(coords)\n",
    "    pcd.paint_uniform_color([1.0, 0.0, 0.0])  # –∫—Ä–∞—Å–Ω—ã–µ —Ç–æ—á–∫–∏\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–º–µ—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–∑—ã)\n",
    "    geometries = [pcd]\n",
    "    for pose in vo.poses:\n",
    "        frustum = create_camera_frustum(scale=5).transform(pose)\n",
    "        geometries.append(frustum)\n",
    "\n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    o3d.visualization.draw_geometries(geometries, window_name=\"MapPoints –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\")\n",
    "\n",
    "# check_and_visualize_mappoints(vo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
